# 11. Градиентный бустинг

## Общая идея

Градиентный бустинг — это ансамблевый метод машинного обучения, в котором модель строится **последовательно** как сумма простых моделей (обычно неглубоких деревьев решений).  
Каждая новая модель **исправляет ошибки текущего ансамбля**, а не обучается независимо.

В отличие от бэггинга и Random Forest, где модели обучаются параллельно и усредняются, в градиентном бустинге модели обучаются **последовательно** и **добавляются** к уже построенной модели.

---

## Вид итоговой модели

Итоговая модель представляется в виде суммы:

$$
f(x) = \sum_{t=0}^{T} f_t(x)
$$

где:
- \( f_0(x) \) — начальное приближение (обычно константа),
- \( f_t(x) \) — вклад модели, построенной на шаге \( t \).

Таким образом, итоговое предсказание формируется как накопление поправок.

---

## Начальное приближение

На первом шаге берётся **самая простая модель**.  
Для задачи регрессии с функцией потерь MSE начальное приближение выбирается как среднее значение таргета:

$$
f_0(x) = \arg\min_c \sum_{i=1}^{n} (y_i - c)^2 = \frac{1}{n} \sum_{i=1}^{n} y_i
$$

Это лучшее возможное константное приближение.

---

## Функция потерь

Градиентный бустинг минимизирует некоторую функцию потерь:

$$
L(y, f(x))
$$

Примеры:
- для регрессии:  
  $$
  L(y, \hat y) = (y - \hat y)^2
  $$
- для классификации: LogLoss и др.

---

## Остатки (антиградиент)

На каждом шаге вычисляется величина, показывающая, **в каком направлении нужно изменить предсказание**, чтобы уменьшить ошибку.

Эта величина называется **антиградиентом функции потерь**:

$$
r_{i,t} = -\frac{\partial L(y_i, f(x_i))}{\partial f(x_i)}
$$

Для MSE:

$$
L = (y - \hat y)^2
$$

$$
r_{i,t} = 2 (y_i - f(x_i))
$$

С точностью до константы это обычный **остаток**:

$$
r_{i,t} \propto y_i - \hat y_i
$$

Остатки показывают, **насколько и в какую сторону текущая модель ошибается**.

---

## Обучение новой модели

На шаге \( t \) обучается новая базовая модель \( h(x, \theta_t) \), которая аппроксимирует остатки:

$$
\theta_t = \arg\min_{\theta} \sum_{i=1}^{n} \left(r_{i,t} - h(x_i, \theta)\right)^2
$$

То есть новая модель обучается **предсказывать остатки**, используя исходные признаки.

Важно:  
мы **не меняем целевую задачу**, а используем остатки как **обучающий сигнал**, показывающий, как скорректировать текущее предсказание.

---

## Обновление модели

После обучения новая модель добавляется к текущему приближению:

$$
f_t(x) = f_{t-1}(x) + \rho_t \, h(x, \theta_t)
$$

где:
- \( \rho_t \) — коэффициент (шаг), определяющий силу добавляемой поправки.

На практике часто используют фиксированный коэффициент \( \eta \) (learning rate):

$$
f_t(x) = f_{t-1}(x) + \eta \, h(x)
$$

---

## Подбор коэффициента

Формально коэффициент выбирается из условия минимизации ошибки:

$$
\rho_t = \arg\min_{\rho} \sum_{i=1}^{n} L\big(y_i, f_{t-1}(x_i) + \rho \, h(x_i)\big)
$$

На практике обычно используют заранее заданный небольшой learning rate.

---

## Итеративный процесс

Алгоритм градиентного бустинга состоит из повторения шагов:
1. есть текущее приближение \( f(x) \);
2. вычисляются остатки (антиградиенты);
3. обучается модель, предсказывающая остатки;
4. модель добавляется к текущему приближению;
5. ошибка уменьшается.

---

## Bias и Variance

- Градиентный бустинг эффективно **уменьшает bias**, так как последовательно исправляет систематические ошибки.
- Variance может увеличиваться при:
  - слишком сложных базовых моделях,
  - большом числе итераций,
  - большом learning rate.

Поэтому градиентный бустинг требует регуляризации.

---

## Сравнение с AdaBoost

- В AdaBoost используется **перевзвешивание объектов** и индивидуальные веса моделей.
- В градиентном бустинге используется **минимизация функции потерь** через антиградиент.
- Градиентный бустинг является более общим и устойчивым методом.

---

## Краткая формулировка для экзамена

Градиентный бустинг — это ансамблевый метод, в котором модель строится как сумма слабых моделей, обучаемых последовательно. На каждом шаге новая модель аппроксимирует антиградиент функции потерь, что для MSE эквивалентно обучению на остатках. Итоговое предсказание получается путём последовательного добавления поправок, что позволяет эффективно уменьшать bias модели.
