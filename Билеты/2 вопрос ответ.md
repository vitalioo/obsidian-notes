## KNN (k-Nearest Neighbors)

### 5. В чём идея KNN?
**KNN** — это алгоритм, который классифицирует новый объект по классам его *k ближайших соседей* в пространстве признаков.

- для **классификации**: выбирается класс, который чаще всего встречается среди соседей  
- для **регрессии**: берётся среднее значение таргета у соседей

Алгоритм не строит явную модель, а использует всю обучающую выборку при предсказании.

---

### 6. Что такое параметр *k*?
Параметр **k** — это количество ближайших соседей, которые учитываются при принятии решения.

- маленькое *k* → высокая чувствительность к шуму, переобучение  
- большое *k* → более сглаженные предсказания, возможное недообучение  

Выбор *k* — это компромисс между **bias** и **variance**.

---

### 7. Расстояния в KNN

#### Евклидово расстояние
Обычное расстояние «по прямой» между двумя точками:

\[
d(x, y) = \sqrt{\sum_{i=1}^{d} (x_i - y_i)^2}
\]

Используется, когда признаки имеют сопоставимые масштабы.

---

#### Манхэттенское расстояние
Расстояние «по улицам города» (без диагоналей):

\[
d(x, y) = \sum_{i=1}^{d} |x_i - y_i|
\]

Часто более устойчиво к выбросам.

---

#### Косинусное расстояние
Оценивает угол между векторами, а не их длину:

\[
\cos(x, y) = \frac{x \cdot y}{\|x\| \|y\|}
\]

Используется, когда важнее направление, чем абсолютные значения (например, в текстах).

---

### 8. Почему KNN плохо работает на больших данных?
Для предсказания одного объекта необходимо посчитать расстояние **до всех объектов обучающей выборки**.

- вычислительная сложность:  
\[
O(n \cdot d)
\]
где \(n\) — число объектов, \(d\) — число признаков

Поэтому KNN:
- медленный при большом размере данных
- требует много памяти
- плохо масштабируется

---

### 9. Зачем масштабировать признаки в KNN?
KNN полностью основан на расстояниях между объектами.

Если признаки имеют разные масштабы (например, возраст и доход), то признак с большим диапазоном будет доминировать в расстоянии.

Пример:
- возраст: 0–100  
- доход: 0–1 000 000  

Без масштабирования расстояние будет определяться почти только доходом.

**Масштабирование** делает вклад всех признаков в расстояние сопоставимым, что критично для корректной работы KNN.
